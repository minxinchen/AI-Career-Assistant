# AI Career Assistant MCPæœå‹™å™¨æ¶æ§‹è¨­è¨ˆ

## ğŸ“‹ æ¦‚è¿°

å°‡AI Career Assistantè½‰æ›ç‚ºMCPï¼ˆModel Context Protocolï¼‰æœå‹™å™¨ï¼Œæ–°å¢å±¥æ­·å•ç­”åŠŸèƒ½ï¼Œä½¿å…¶å¯è¢«ä»»ä½•MCPå®¢æˆ¶ç«¯ï¼ˆå¦‚Claude Desktopã€IDEsç­‰ï¼‰èª¿ç”¨ã€‚

## ğŸ—ï¸ MCPæœå‹™å™¨æ¶æ§‹

### æ ¸å¿ƒæ¶æ§‹åœ–

```mermaid
graph TB
    subgraph "MCPå®¢æˆ¶ç«¯ç”Ÿæ…‹"
        C1[Claude Desktop]
        C2[VS Code + MCP]
        C3[å…¶ä»–MCPå®¢æˆ¶ç«¯]
    end
    
    subgraph "ACA MCPæœå‹™å™¨"
        MCP[MCP Protocol Handler]
        
        subgraph "æ ¸å¿ƒæœå‹™"
            RS[Resume Service]
            QA[QA Service] 
            VS[Vector Search]
            AI[AI Analysis]
        end
        
        subgraph "MCPæ¥å£"
            T[Tools]
            R[Resources]
            P[Prompts]
        end
        
        subgraph "æ•¸æ“šå±¤"
            VDB[(Vector DB)]
            CACHE[(Redis Cache)]
            FILE[File Storage]
        end
    end
    
    C1 <-->|JSON-RPC| MCP
    C2 <-->|JSON-RPC| MCP
    C3 <-->|JSON-RPC| MCP
    
    MCP --> T
    MCP --> R
    MCP --> P
    
    T --> RS
    T --> QA
    R --> VS
    P --> AI
    
    RS <--> FILE
    QA <--> VDB
    VS <--> VDB
    AI <--> CACHE
```

## ğŸ”§ MCPæœå‹™æ¥å£è¨­è¨ˆ

### 1. Toolsï¼ˆå·¥å…·æ¥å£ï¼‰

#### `analyze_resume`
```json
{
  "name": "analyze_resume",
  "description": "åˆ†æä¸Šå‚³çš„å±¥æ­·ä¸¦æå–é—œéµä¿¡æ¯",
  "inputSchema": {
    "type": "object",
    "properties": {
      "file_content": {
        "type": "string",
        "description": "å±¥æ­·æª”æ¡ˆå…§å®¹ï¼ˆbase64ç·¨ç¢¼ï¼‰"
      },
      "file_type": {
        "type": "string", 
        "enum": ["pdf", "docx"],
        "description": "æª”æ¡ˆé¡å‹"
      },
      "analysis_depth": {
        "type": "string",
        "enum": ["basic", "detailed", "comprehensive"],
        "default": "detailed"
      }
    },
    "required": ["file_content", "file_type"]
  }
}
```

#### `ask_resume_question`
```json
{
  "name": "ask_resume_question",
  "description": "å°å±¥æ­·å…§å®¹æå•ä¸¦ç²å¾—æ™ºèƒ½å›ç­”",
  "inputSchema": {
    "type": "object",
    "properties": {
      "question": {
        "type": "string",
        "description": "é—œæ–¼å±¥æ­·çš„å•é¡Œ"
      },
      "resume_id": {
        "type": "string",
        "description": "å±¥æ­·IDï¼ˆä¾†è‡ªanalyze_resumeçš„çµæœï¼‰"
      },
      "context_window": {
        "type": "integer",
        "default": 3,
        "description": "æœç´¢ä¸Šä¸‹æ–‡çª—å£å¤§å°"
      }
    },
    "required": ["question", "resume_id"]
  }
}
```

#### `search_job_matches`
```json
{
  "name": "search_job_matches",
  "description": "åŸºæ–¼å±¥æ­·å°‹æ‰¾åŒ¹é…çš„è·ç¼º",
  "inputSchema": {
    "type": "object",
    "properties": {
      "resume_id": {
        "type": "string",
        "description": "å±¥æ­·ID"
      },
      "job_preferences": {
        "type": "object",
        "properties": {
          "location": {"type": "string"},
          "salary_range": {"type": "object"},
          "remote_work": {"type": "boolean"}
        }
      },
      "match_count": {
        "type": "integer",
        "default": 10,
        "description": "è¿”å›çš„è·ç¼ºæ•¸é‡"
      }
    },
    "required": ["resume_id"]
  }
}
```

### 2. Resourcesï¼ˆè³‡æºæ¥å£ï¼‰

#### å±¥æ­·å…§å®¹è³‡æº
```json
{
  "uri": "resume://{resume_id}/content",
  "name": "å±¥æ­·åŸå§‹å…§å®¹",
  "description": "å®Œæ•´çš„å±¥æ­·æ–‡æœ¬å…§å®¹",
  "mimeType": "text/plain"
}
```

#### åˆ†æçµæœè³‡æº
```json
{
  "uri": "resume://{resume_id}/analysis",
  "name": "å±¥æ­·åˆ†æçµæœ", 
  "description": "çµæ§‹åŒ–çš„å±¥æ­·åˆ†ææ•¸æ“š",
  "mimeType": "application/json"
}
```

#### è·ç¼ºåŒ¹é…è³‡æº
```json
{
  "uri": "resume://{resume_id}/job-matches",
  "name": "è·ç¼ºåŒ¹é…çµæœ",
  "description": "åŸºæ–¼å±¥æ­·çš„è·ç¼ºæ¨è–¦åˆ—è¡¨",
  "mimeType": "application/json"
}
```

### 3. Promptsï¼ˆæç¤ºæ¨¡æ¿ï¼‰

#### å±¥æ­·åˆ†ææç¤º
```json
{
  "name": "analyze_resume_prompt",
  "description": "å°ˆæ¥­å±¥æ­·åˆ†ææç¤ºæ¨¡æ¿",
  "arguments": [
    {
      "name": "resume_content",
      "description": "å±¥æ­·å…§å®¹æ–‡æœ¬",
      "required": true
    },
    {
      "name": "focus_area", 
      "description": "åˆ†æé‡é»é ˜åŸŸ",
      "required": false
    }
  ]
}
```

#### å•ç­”æç¤º
```json
{
  "name": "resume_qa_prompt",
  "description": "å±¥æ­·å•ç­”å°è©±æç¤ºæ¨¡æ¿",
  "arguments": [
    {
      "name": "question",
      "description": "ç”¨æˆ¶å•é¡Œ",
      "required": true
    },
    {
      "name": "context",
      "description": "ç›¸é—œå±¥æ­·ä¸Šä¸‹æ–‡",
      "required": true
    }
  ]
}
```

## ğŸ’¾ æ•¸æ“šæ¶æ§‹è¨­è¨ˆ

### å±¥æ­·æ•¸æ“šçµæ§‹
```json
{
  "resume_id": "uuid-string",
  "metadata": {
    "upload_time": "2025-01-01T12:00:00Z",
    "file_type": "pdf",
    "file_size": 2048576,
    "processing_status": "completed"
  },
  "content": {
    "raw_text": "åŸå§‹æ–‡æœ¬å…§å®¹...",
    "structured_data": {
      "basic_info": {...},
      "education": [...],
      "experience": [...],
      "skills": [...],
      "achievements": [...]
    }
  },
  "analysis": {
    "summary": "å±¥æ­·æ‘˜è¦",
    "strengths": [...],
    "suggestions": [...],
    "career_level": "ä¸­ç´š"
  },
  "vectors": {
    "content_embedding": [0.1, 0.2, ...],
    "skills_embedding": [0.3, 0.4, ...],
    "experience_embedding": [0.5, 0.6, ...]
  }
}
```

### å‘é‡æœç´¢æ¶æ§‹
```yaml
å‘é‡æ•¸æ“šåº«è¨­è¨ˆ:
  collection: "resume_chunks"
  vector_dimension: 1536  # OpenAI embedding
  ç´¢å¼•é¡å‹: HNSW
  ç›¸ä¼¼åº¦è¨ˆç®—: cosine
  
åˆ†å¡Šç­–ç•¥:
  - æŒ‰æ®µè½åˆ†å¡Š (max 512 tokens)
  - é‡ç–Šçª—å£ (50 tokens overlap)
  - èªç¾©é‚Šç•Œè­˜åˆ¥
  
æª¢ç´¢ç­–ç•¥:
  - æ··åˆæœç´¢ (å‘é‡ + é—œéµè©)
  - é‡æ’åº (Reranking)
  - ä¸Šä¸‹æ–‡èåˆ
```

## ğŸ”„ å•ç­”ç³»çµ±å·¥ä½œæµç¨‹

### 1. å±¥æ­·ä¸Šå‚³èˆ‡è™•ç†
```mermaid
sequenceDiagram
    participant C as MCPå®¢æˆ¶ç«¯
    participant S as MCPæœå‹™å™¨
    participant V as å‘é‡æ•¸æ“šåº«
    participant A as AIæœå‹™
    
    C->>S: analyze_resume(file_content)
    S->>S: æ–‡ä»¶è§£æ & OCR
    S->>A: å…§å®¹çµæ§‹åŒ–åˆ†æ
    A->>S: çµæ§‹åŒ–æ•¸æ“š
    S->>A: ç”Ÿæˆå‘é‡åµŒå…¥
    A->>S: å‘é‡æ•¸æ“š
    S->>V: å­˜å„²å‘é‡å’Œå…§å®¹
    S->>C: è¿”å›resume_idå’Œåˆ†æçµæœ
```

### 2. å•ç­”æŸ¥è©¢æµç¨‹
```mermaid
sequenceDiagram
    participant C as MCPå®¢æˆ¶ç«¯
    participant S as MCPæœå‹™å™¨
    participant V as å‘é‡æ•¸æ“šåº«
    participant A as AIæœå‹™
    
    C->>S: ask_resume_question(question, resume_id)
    S->>A: å•é¡Œå‘é‡åŒ–
    A->>S: å•é¡Œå‘é‡
    S->>V: å‘é‡ç›¸ä¼¼æ€§æœç´¢
    V->>S: ç›¸é—œå…§å®¹ç‰‡æ®µ
    S->>A: å•é¡Œ+ä¸Šä¸‹æ–‡ â†’ LLMæ¨ç†
    A->>S: æ™ºèƒ½å›ç­”
    S->>C: æ ¼å¼åŒ–å›ç­” + è­‰æ“šä¾†æº
```

### 3. ä¸Šä¸‹æ–‡ç®¡ç†
```yaml
æœƒè©±ç®¡ç†:
  - session_id: å”¯ä¸€æœƒè©±æ¨™è­˜
  - conversation_history: å°è©±æ­·å²
  - context_window: æ»‘å‹•çª—å£ä¸Šä¸‹æ–‡
  - memory_retention: é—œéµä¿¡æ¯ä¿æŒ

ä¸Šä¸‹æ–‡èåˆ:
  - çŸ­æœŸè¨˜æ†¶: ç•¶å‰å°è©±å…§å®¹
  - é•·æœŸè¨˜æ†¶: å±¥æ­·çµæ§‹åŒ–æ•¸æ“š
  - èªç¾©è¨˜æ†¶: å‘é‡æœç´¢çµæœ
  - ç¨‹åºè¨˜æ†¶: åˆ†ææ¨¡æ¿å’Œè¦å‰‡
```

## ğŸ› ï¸ å¯¦æ–½æŠ€è¡“æ£§

### MCPæœå‹™å™¨å¯¦ç¾
```typescript
// åŸºæ–¼å®˜æ–¹TypeScript SDK
import { Server } from "@modelcontextprotocol/sdk/server/index.js";
import { StdioServerTransport } from "@modelcontextprotocol/sdk/server/stdio.js";

const server = new Server({
  name: "ai-career-assistant-mcp",
  version: "1.0.0"
}, {
  capabilities: {
    tools: {},
    resources: {},
    prompts: {}
  }
});
```

### å‘é‡æœç´¢æœå‹™
```python
# ä½¿ç”¨Pineconeæˆ–Weaviate
import pinecone
from sentence_transformers import SentenceTransformer

class ResumeVectorSearch:
    def __init__(self):
        self.encoder = SentenceTransformer('all-MiniLM-L6-v2')
        self.index = pinecone.Index("resume-vectors")
    
    async def search_similar_content(self, query: str, resume_id: str, top_k=5):
        query_vector = self.encoder.encode([query])
        results = self.index.query(
            vector=query_vector[0].tolist(),
            filter={"resume_id": resume_id},
            top_k=top_k,
            include_metadata=True
        )
        return results.matches
```

### AIå•ç­”æœå‹™
```python
from openai import AsyncOpenAI

class ResumeQAService:
    def __init__(self):
        self.client = AsyncOpenAI()
    
    async def answer_question(self, question: str, context: list[str]):
        prompt = f"""
        åŸºæ–¼ä»¥ä¸‹å±¥æ­·å…§å®¹å›ç­”å•é¡Œ:
        
        å±¥æ­·å…§å®¹: {' '.join(context)}
        
        å•é¡Œ: {question}
        
        è«‹æä¾›æº–ç¢ºã€å…·é«”çš„å›ç­”ï¼Œä¸¦å¼•ç”¨ç›¸é—œçš„å±¥æ­·å…§å®¹ä½œç‚ºè­‰æ“šã€‚
        """
        
        response = await self.client.chat.completions.create(
            model="gpt-4",
            messages=[{"role": "user", "content": prompt}]
        )
        
        return response.choices[0].message.content
```

## ğŸ”’ å®‰å…¨èˆ‡éš±ç§è¨­è¨ˆ

### æ•¸æ“šä¿è­·æ©Ÿåˆ¶
```yaml
éš±ç§ä¿è­·:
  - å±¥æ­·æ•¸æ“šåŠ å¯†å­˜å„²
  - å‚³è¼¸éç¨‹TLSåŠ å¯†
  - å®šæœŸæ•¸æ“šæ¸…ç†ï¼ˆ30å¤©TTLï¼‰
  - ç”¨æˆ¶æ•¸æ“šåŒ¿ååŒ–é¸é …

è¨ªå•æ§åˆ¶:
  - API Keyèªè­‰
  - è«‹æ±‚é »ç‡é™åˆ¶
  - IPç™½åå–®ï¼ˆå¯é¸ï¼‰
  - å¯©è¨ˆæ—¥èªŒè¨˜éŒ„

æ•¸æ“šåˆè¦:
  - GDPRåˆè¦è¨­è¨ˆ
  - æ•¸æ“šæœ€å°åŒ–åŸå‰‡
  - ç”¨æˆ¶æ•¸æ“šåˆªé™¤æ¬Š
  - é€æ˜çš„éš±ç§æ”¿ç­–
```

## ğŸ“Š æ•ˆèƒ½æŒ‡æ¨™

### ç›®æ¨™æ•ˆèƒ½æ¨™æº–
```yaml
éŸ¿æ‡‰æ™‚é–“:
  - å±¥æ­·åˆ†æ: <30ç§’
  - å•ç­”æŸ¥è©¢: <3ç§’
  - å‘é‡æœç´¢: <500ms
  
ä½µç™¼èƒ½åŠ›:
  - åŒæ™‚è™•ç†: 10å€‹åˆ†æè«‹æ±‚
  - QPS: 100æ¬¡å•ç­”/ç§’
  
æº–ç¢ºæ€§:
  - å•ç­”æº–ç¢ºç‡: >90%
  - æœç´¢ç›¸é—œæ€§: >85%
  - åˆ†æå®Œæ•´æ€§: >95%
```

## ğŸš€ éƒ¨ç½²æ¶æ§‹

### Dockerå®¹å™¨åŒ–éƒ¨ç½²
```yaml
services:
  mcp-server:
    build: ./mcp-server
    ports:
      - "8080:8080"
    environment:
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - PINECONE_API_KEY=${PINECONE_API_KEY}
    
  vector-db:
    image: weaviate/weaviate:latest
    ports:
      - "8081:8080"
    
  redis:
    image: redis:alpine
    ports:
      - "6379:6379"
```

### MCPå®¢æˆ¶ç«¯é…ç½®
```json
{
  "mcpServers": {
    "ai-career-assistant": {
      "command": "node",
      "args": ["/path/to/mcp-server.js"],
      "env": {
        "OPENAI_API_KEY": "your-key-here"
      }
    }
  }
}
```

## ğŸ“‹ é–‹ç™¼é‡Œç¨‹ç¢‘

### Phase 1: MCPåŸºç¤æ¶æ§‹ (1é€±)
- [ ] MCPæœå‹™å™¨æ¡†æ¶æ­å»º
- [ ] åŸºç¤Toolsæ¥å£å¯¦ç¾
- [ ] ç°¡å–®çš„å±¥æ­·è§£æåŠŸèƒ½

### Phase 2: å‘é‡æœç´¢ç³»çµ± (1é€±)
- [ ] å‘é‡æ•¸æ“šåº«é›†æˆ
- [ ] å±¥æ­·å…§å®¹å‘é‡åŒ–
- [ ] èªç¾©æœç´¢åŠŸèƒ½

### Phase 3: å•ç­”ç³»çµ± (1é€±)
- [ ] AIå•ç­”æœå‹™å¯¦ç¾
- [ ] ä¸Šä¸‹æ–‡ç®¡ç†æ©Ÿåˆ¶
- [ ] å°è©±æ­·å²åŠŸèƒ½

### Phase 4: é›†æˆæ¸¬è©¦ (1é€±)
- [ ] ç«¯åˆ°ç«¯åŠŸèƒ½æ¸¬è©¦
- [ ] æ•ˆèƒ½å„ªåŒ–èª¿æ•´
- [ ] Claude Desktopæ•´åˆæ¸¬è©¦

---

**æ–‡æª”ç‰ˆæœ¬**: v1.0  
**å‰µå»ºæ™‚é–“**: 2025-08-05  
**æ›´æ–°è€…**: AI Architecture Team