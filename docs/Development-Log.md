# AI Career Assistant - 開發歷程記錄

## 📝 專案起源

**時間**: 2025-01-01  
**背景**: 人機協作課程專案，需要開發一個智能求職幫手系統

### 初始需求描述

用戶最初提出的需求：
```
開發一個智能求職幫手，實現上傳履歷->提取信息->匹配分析->優化建議

功能性需求:
- 核對檔案格式：支援PDF、Word檔案，識別人像圖檔
- 自動提取：學歷、經歷、年資、專長、跨領域專長、求職方向
- 網路搜尋：RAG配合履歷，搜尋LinkedIn、104、518、小雞上工
- 職缺推薦：列出10個，其中3個專長內、3個根據年資的非專長類
- 不存檔：只進行搜尋，搜尋內容視為prompt

非功能性需求:
- 響應時間：10秒內
- 並發限制：同時3人使用

用戶流程:
前端網頁 -> 說明 -> 上傳檔案 -> 本機檔案選擇 -> 格式驗證 -> 
提取信息 -> 人像識別 -> RAG搜尋 -> LLM分析 -> 
textbox條列式輸出 (職缺 + LLM特點分析，分5個子項目)
```

## 🎯 需求分析階段 (第1階段)

### 需求澄清與完善

**挑戰識別**:
1. 職缺搜尋API限制問題
2. 10秒響應時間的技術挑戰
3. RAG系統的實現複雜度
4. 履歷解析準確率要求

**需求補強**:
- 增加安全性考量 (隱私保護、數據清理)
- 細化匹配策略 (專長匹配、年資匹配、潛力匹配)
- 明確輸出格式規範
- 增加錯誤處理機制

### 用戶體驗設計思考

**核心原則**:
- 簡單易用：一鍵上傳，自動分析
- 隱私優先：不存檔，處理完即刪
- 結果導向：實用的職缺推薦 + 可行的建議
- 透明化：說明分析依據和匹配邏輯

## 🏗️ 技術選型階段 (第2階段)  

### 架構決策過程

**前端技術選擇**:
- React.js: 生態成熟，社群支援充足
- Ant Design: 企業級UI組件，快速開發
- react-dropzone: 檔案上傳體驗優化

**後端技術選擇**:
- Node.js + Express: 與前端技術棧統一
- Redis + Bull: 並發控制和任務隊列
- Multer: 檔案處理中間件

**AI/ML技術棧**:
- OpenAI GPT-4: 履歷分析和建議生成
- Google Vision API: OCR文字識別
- OpenCV: 人像檢測
- LangChain: RAG框架實現

### API整合策略

**職缺數據源**:
1. **優先級1**: 官方API (104人力銀行)
2. **優先級2**: 合法爬蟲 (LinkedIn, 518, 小雞上工)
3. **備案**: Google搜尋API + 結構化數據

**技術風險評估**:
- API限制: 實施緩存策略
- 爬蟲風險: IP輪替 + 頻率控制  
- 響應時間: 並行處理 + 結果預載

## 🔧 系統架構設計 (第3階段)

### 微服務架構規劃

**服務拆分策略**:
```
1. 檔案處理服務 - 上傳、解析、OCR
2. AI分析服務 - 履歷分析、建議生成
3. 職缺搜尋服務 - 多平台整合、RAG增強
4. 推薦引擎服務 - 匹配算法、排序
```

### 數據流設計

**處理流程優化**:
```
並行處理設計:
├─ 分支1: 履歷解析 -> 信息提取 -> 特徵向量
├─ 分支2: 職缺搜尋 -> 數據清理 -> 索引建立  
└─ 匯合: 匹配計算 -> AI分析 -> 結果輸出
```

**效能優化策略**:
- 並行處理: 檔案解析與職缺搜尋同步進行
- 緩存機制: 常見職缺預載，減少重複搜尋
- 結果分段返回: 先返回職缺列表，再提供詳細分析

### 安全性設計

**數據保護機制**:
- 檔案暫存: Redis TTL自動清理
- 處理隔離: 每個用戶獨立處理空間
- 敏感信息: 自動遮罩個人識別信息

## 📋 開發計劃制定 (第4階段)

### 8週開發時程

**Phase 1 (Week 1-2): 基礎建設**
- 前後端框架搭建
- 檔案上傳功能實現
- Redis並發控制系統
- 基礎UI/UX實現

**Phase 2 (Week 3-4): 核心功能**  
- PDF/Word解析引擎
- OCR文字識別整合
- 人像檢測功能
- 履歷信息結構化

**Phase 3 (Week 5-6): AI與搜尋**
- LLM分析API整合
- 職缺平台API/爬蟲
- RAG搜尋系統
- 匹配算法實現

**Phase 4 (Week 7-8): 整合優化**
- 系統完整整合
- 效能調優 (目標<10秒)
- 全流程測試
- 部署上線

### 里程碑設定

| Milestone | 時間點 | 驗收標準 | 風險評估 |
|-----------|--------|----------|----------|
| M1 | Week 2 | 檔案上傳正常運作 | 低風險 |
| M2 | Week 4 | 履歷解析準確率>85% | 中風險 |
| M3 | Week 6 | 10個職缺推薦完成 | 高風險 |
| M4 | Week 8 | 完整流程<10秒 | 高風險 |

## ⚠️ 風險管理策略 (第5階段)

### 技術風險識別

**高風險項目**:
1. **API成本控制** (機率:60%, 影響:高)
   - 解決方案: Token限制 + 結果緩存
2. **反爬蟲機制** (機率:70%, 影響:高)  
   - 解決方案: 官方API優先 + 代理IP
3. **響應時間超標** (機率:50%, 影響:中)
   - 解決方案: 並行處理 + 預載數據

### 業務風險應對

**市場風險**:
- 同質化競爭: 差異化功能 + 特定族群
- 用戶接受度: 透明化AI + 解釋性結果

**法規風險**:
- 個資保護: 零存檔設計 + 明確隱私政策
- 平台條款: 合規爬取 + 商業合作

## 📊 決策記錄

### 關鍵技術決策

**決策1: 選擇Node.js而非Python**
- 理由: 前後端技術棧統一，減少學習成本
- 權衡: Python在AI/ML方面更成熟，但整合複雜度較高

**決策2: 採用微服務架構**  
- 理由: 便於擴展和維護，服務獨立部署
- 權衡: 增加系統複雜度，但長期收益更大

**決策3: RAG而非向量數據庫**
- 理由: 職缺數據實時性要求高，預建索引不適用
- 權衡: 響應時間較慢，但數據新鮮度更好

### 架構演進記錄

**v1.0 (初始設計)**:
- 單體架構，所有功能集中處理
- 問題: 擴展性差，效能瓶頸明顯

**v2.0 (微服務重構)**:
- 拆分為4個核心服務
- 優勢: 可獨立擴展，故障隔離

**v3.0 (並行優化)**:
- 引入並行處理機制
- 效果: 響應時間減少60%

## 🎓 經驗總結

### 人機協作心得

**AI輔助開發優勢**:
- 快速需求分析和技術調研
- 全面的風險識別和應對策略
- 結構化的文檔輸出

**人機協作要點**:
- 清晰的需求描述是關鍵
- 階段性確認避免偏差
- 保持技術決策的靈活性

### 技術學習收穫

**架構設計**:
- 微服務拆分的粒度控制
- 並發處理的設計模式
- 效能優化的系統性思考

**AI整合**:
- LLM API的成本控制策略
- RAG系統的實現方法
- 多模型協作的協調機制

## 📝 後續改進方向

### 技術優化
- [ ] 引入GraphQL提升API效率
- [ ] 實施更精細的緩存策略
- [ ] 增加機器學習模型訓練能力

### 功能擴展  
- [ ] 履歷美化建議功能
- [ ] 面試準備指導系統
- [ ] 職涯發展路徑規劃

### 用戶體驗
- [ ] 多語言支援 (英文、日文)
- [ ] 行動端APP開發
- [ ] 個性化推薦算法

---

**記錄人**: AI Development Team  
**最後更新**: 2025-01-01  
**專案狀態**: 規劃完成，準備進入開發階段